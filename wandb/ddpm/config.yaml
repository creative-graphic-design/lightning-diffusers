# lightning.pytorch==2.5.1
seed_everything: 0
trainer:
  accelerator: auto
  strategy: auto
  devices: 1
  num_nodes: 1
  precision: null
  logger:
    class_path: lightning.pytorch.loggers.WandbLogger
    init_args:
      name: ddpm
      save_dir: wandb/ddpm
      version: null
      offline: false
      dir: null
      id: null
      anonymous: null
      project: mnist
      log_model: false
      experiment: null
      prefix: ''
      checkpoint_name: null
      entity: null
      notes: null
      tags:
      - mnist
      - ddpm
      config: null
      config_exclude_keys: null
      config_include_keys: null
      allow_val_change: null
      group: null
      job_type: null
      mode: null
      force: null
      reinit: null
      resume: null
      resume_from: null
      fork_from: null
      save_code: null
      tensorboard: null
      sync_tensorboard: null
      monitor_gym: null
      settings: null
  callbacks:
    class_path: lightning_diffusers.callbacks.MnistDDPMCallback
    init_args:
      num_generate_images: 16
      num_grid_rows: 4
      num_grid_cols: 4
  fast_dev_run: false
  max_epochs: 10
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  limit_predict_batches: null
  overfit_batches: 0.0
  val_check_interval: null
  check_val_every_n_epoch: 1
  num_sanity_val_steps: null
  log_every_n_steps: null
  enable_checkpointing: null
  enable_progress_bar: null
  enable_model_summary: null
  accumulate_grad_batches: 1
  gradient_clip_val: null
  gradient_clip_algorithm: null
  deterministic: null
  benchmark: null
  inference_mode: true
  use_distributed_sampler: true
  profiler: null
  detect_anomaly: false
  barebones: false
  plugins: null
  sync_batchnorm: false
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: null
  model_registry: null
model:
  class_path: lightning_diffusers.models.MnistDDPMModule
  init_args:
    unet:
      class_path: diffusers.UNet2DModel
      init_args:
        sample_size: 32
        in_channels: 1
        out_channels: 1
        center_input_sample: false
        time_embedding_type: positional
        time_embedding_dim: null
        freq_shift: 0
        flip_sin_to_cos: true
        down_block_types:
        - DownBlock2D
        - DownBlock2D
        - DownBlock2D
        - DownBlock2D
        mid_block_type: UNetMidBlock2D
        up_block_types:
        - UpBlock2D
        - UpBlock2D
        - UpBlock2D
        - UpBlock2D
        block_out_channels:
        - 64
        - 128
        - 256
        - 512
        layers_per_block: 3
        mid_block_scale_factor: 1.0
        downsample_padding: 1
        downsample_type: conv
        upsample_type: conv
        dropout: 0.0
        act_fn: silu
        attention_head_dim: 8
        norm_num_groups: 32
        attn_norm_num_groups: null
        norm_eps: 1.0e-05
        resnet_time_scale_shift: default
        add_attention: true
        class_embed_type: null
        num_class_embeds: null
        num_train_timesteps: null
    noise_scheduler:
      class_path: diffusers.DDPMScheduler
      init_args:
        num_train_timesteps: 500
        beta_start: 0.0001
        beta_end: 0.02
        beta_schedule: linear
        trained_betas: null
        variance_type: fixed_small
        clip_sample: true
        prediction_type: epsilon
        thresholding: false
        dynamic_thresholding_ratio: 0.995
        clip_sample_range: 1.0
        sample_max_value: 1.0
        timestep_spacing: leading
        steps_offset: 0
        rescale_betas_zero_snr: false
    optimizer:
      class_path: torch.optim.AdamW
      init_args:
        lr: 0.0001
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        amsgrad: false
        maximize: false
        foreach: null
        capturable: false
        differentiable: false
        fused: null
data:
  class_path: lightning_diffusers.data.MnistDataModule
  init_args:
    data_dir: data
    sample_size: 32
    batch_size: 256
optimizer: null
lr_scheduler: null
ckpt_path: null
